---
title: "Ensemble Trees"
author: "Ravi Brenner"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
data(ames)
data(credit_data)
```

```{r}
set.seed(2025)

ames_split <- initial_split(ames, prop = 0.8)
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
ames_cv <- vfold_cv(ames_train)

credit_split <- initial_split(credit_data, prop = 0.8, strata = Status)
credit_train <- training(credit_split)
credit_test <- testing(credit_split)
credit_cv <- vfold_cv(credit_train)


reg_recipe <- 
  recipe(Sale_Price ~ ., data = ames_train)
```

```{r}
# Calculate the test set bias, variance, MSE with bootstrapping
bootstrap_predictions <- function(workflow_in, train_data, test_data){
  fit_model <- function(split, workflow) {
    fit(workflow, data = training(split))
  }
  
  set.seed(2025)
  ames_bootstraps <- bootstraps(train_data, times = 100)
  
  all_predictions <-
    ames_bootstraps |>
    mutate(
      model_fit = map(splits, fit_model, workflow = workflow_in),
      predictions = map(model_fit, ~ predict(.x, new_data = test_data) |> rename(pred = .pred))
    )
  
  prediction_df <-
    all_predictions |>
    select(id, predictions) |>
    unnest(predictions) |>
    group_by(id) |>
    mutate(Sale_Price = rep(test_data$Sale_Price, length.out = n()),
           obs_id = row_number()) |>
    ungroup()
  
  return(prediction_df)
}

bias_var_mse <- function(pred_df){
  mse_df <-
    pred_df |>
    group_by(obs_id) |>
    summarise(
      bias_sq = (mean(pred) - mean(Sale_Price))^2,
      variance = stats::var(pred),
      mse = mean((pred - Sale_Price)^2),
      sale_price = first(Sale_Price)
    ) |>
    ungroup() |>
    summarise(
      mean_bias_sq = mean(bias_sq),
      mean_variance = mean(variance),
      mean_mse = mean(mse),
      irr_error = mean_mse - mean_bias_sq - mean_variance
    )
  return(mse_df)
}
```


# Regression case

## Deep CART
as a baseline


```{r}
set.seed(2025)
cart_mod <- 
  decision_tree(mode = "regression",
                engine = "rpart",
                cost_complexity = 0,
                tree_depth = 30,
                min_n = 20) 

reg_recipe <- 
  recipe(Sale_Price ~ ., data = ames_train)

cart_workflow <- 
  workflow() |> 
  add_model(cart_mod) |> 
  add_recipe(reg_recipe)

cart_fit <- fit(cart_workflow,
                data = ames_train)

cart_boot_preds <- bootstrap_predictions(cart_workflow, ames_train, ames_test)

cart_tradeoff <- bias_var_mse(cart_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```




## Shallow CART

```{r}
set.seed(2025)
cart_mod_short <- 
  decision_tree(mode = "regression",
                engine = "rpart",
                cost_complexity = 0,
                tree_depth = 3,
                min_n = 20) 

cart_short_workflow <- 
  workflow() |> 
  add_model(cart_mod_short) |> 
  add_recipe(reg_recipe)

cart_short_fit <- fit(cart_short_workflow,
                      data = ames_train)

cart_short_boot_preds <- bootstrap_predictions(cart_short_workflow, ames_train, ames_test)

cart_short_tradeoff <- bias_var_mse(cart_short_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```


## Bagging

```{r}
set.seed(2025)
bag_mod <- 
  rand_forest(mode = "regression",
              engine = "ranger",
              mtry = ncol(ames) - 1,
              trees = 100,
              min_n = 20) 

bag_workflow <- 
  workflow() |> 
  add_model(bag_mod) |> 
  add_recipe(reg_recipe)

bag_fit <-
  bag_workflow |>
  fit(data = ames_train)

bag_boot_preds <- bootstrap_predictions(bag_workflow, ames_train, ames_test)

bag_tradeoff <- bias_var_mse(bag_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```


Show that variance is reduced relative to CART

## Random Forests

should reduce variance relative to bagging, especially when predictors are correlated may need to sim this

```{r}
set.seed(2025)
rf_mod <- 
  rand_forest(mode = "regression",
              engine = "ranger",
              mtry = floor((ncol(ames) - 1)/3),
              trees = 100,
              min_n = 20)

rf_workflow <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(reg_recipe)

rf_fit <-
  rf_workflow |>
  fit(data = ames_train)

rf_boot_preds <- bootstrap_predictions(rf_workflow, ames_train, ames_test)

rf_tradeoff <- bias_var_mse(rf_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))

```

### Too complex s.t. bias starts to increase more and mse starts to increase tooo
i think rf with a smaller mtry would work

```{r}
set.seed(2025)
rf_short_mod <- 
  rand_forest(mode = "regression",
              engine = "ranger",
              mtry = 3,
              trees = 100,
              min_n = 20) 

rf_short_workflow <- 
  workflow() |> 
  add_model(rf_short_mod) |> 
  add_recipe(reg_recipe)

rf_short_fit <-
  rf_short_workflow |>
  fit(data = ames_train)


rf_short_boot_preds <- bootstrap_predictions(rf_short_workflow, ames_train, ames_test)

rf_short_tradeoff <- bias_var_mse(rf_short_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```

## comparison

```{r}
cart_short_tradeoff |>
  mutate(name = "1. CART Short") |>
  bind_rows(cart_tradeoff |>
              mutate(name = "2. CART Deep")) |>
  bind_rows(bag_tradeoff |>
              mutate(name = "3. Bagging")) |>
  bind_rows(rf_tradeoff |>
              mutate(name = "4. RF")) |>
  bind_rows(rf_short_tradeoff |>
              mutate(name = "5. RF small")) |>
  pivot_longer(cols = c(mean_bias_sq, mean_variance, irr_error),
               names_to = "variable",
               values_to = "value") |>
  ggplot(aes(x = name)) +
  geom_bar(aes(y = value, fill = variable),
           position = "stack", stat = "identity")
```

## how well does CV and OOB approximate the error?
```{r}
cart_res <- fit_resamples(cart_workflow,
                          control = control_resamples(save_workflow = TRUE),
                          metrics = metric_set(rmse),
                          resamples = ames_cv)

bag_res <- fit_resamples(bag_workflow,
                          control = control_resamples(save_workflow = TRUE),
                          metrics = metric_set(rmse),
                          resamples = ames_cv)

rf_res <- fit_resamples(rf_workflow,
                          control = control_resamples(save_workflow = TRUE),
                          metrics = metric_set(rmse),
                          resamples = ames_cv)

cart_res |> 
  collect_metrics()

cart_tradeoff$rmse

bag_res |>
  collect_metrics()

bag_fit |> 
  extract_fit_engine() |>
  pluck("prediction.error") |>
  sqrt()

bag_tradeoff$rmse

rf_res |>
  collect_metrics()

rf_fit |> 
  extract_fit_engine() |>
  pluck("prediction.error") |>
  sqrt()

rf_tradeoff$rmse
```




# classification

```{r}
class_bootstrap <- function(workflow_in, train_data, test_data){
  fit_model <- function(split, workflow) {
    fit(workflow, data = training(split))
  }
  
  set.seed(2025)
  bootstrap_data <- bootstraps(train_data, times = 101)
  
  all_predictions <-
    bootstrap_data |>
    mutate(
      model_fit = map(splits, fit_model, workflow = workflow_in),
      predictions = map(model_fit, ~ predict(.x, new_data = test_data, type = "prob") |> 
                          mutate(pred = if_else(.pred_good >= .pred_bad,"good","bad")))
    )
  
  prediction_df <-
    all_predictions |>
    select(id, predictions) |>
    unnest(predictions) |>
    group_by(id) |>
    mutate(Status = rep(test_data$Status, length.out = n()),
           obs_id = row_number()) |>
    ungroup()
  
  return(prediction_df)
}

bias_var_mse_class <- function(pred_df){
  mse_df <-
    pred_df |>
    mutate(status_int = if_else(Status == "good",1,0)) |>
    group_by(obs_id) |>
    summarise(
      mode_class = DescTools::Mode(pred),
      bias = mean(mode_class != Status),
      bias_2 = (mean(.pred_good) - mean(status_int))^2,
      variance = mean(pred != mode_class),
      variance_2 = stats::var(.pred_good),
      mse = mean((.pred_good - status_int)^2),
      loss = mean(pred != Status)
    ) |>
    ungroup() |>
    summarize(mean_bias = mean(bias),
              mean_var = mean(variance),
              mean_loss = mean(loss),     
              mean_bias_2 = mean(bias_2),
              mean_var_2 = mean(variance_2),
              mean_mse = mean(mse),
              irr_error = mean_mse - mean_var_2 - mean_bias_2)
  
  return(mse_df)
}

cart_class_boot_preds |>
mutate(status_int = if_else(Status == "good",1,0)) |>
    group_by(obs_id) |>
    summarise(
      mode_class = DescTools::Mode(pred),
      bias = mean(mode_class != Status),
      bias_2 = (mean(.pred_good) - mean(status_int))^2,
      variance = mean(pred != mode_class),
      variance_2 = stats::var(.pred_good),
      mse = mean((.pred_good - status_int)^2),
      loss = mean(pred != Status)
    ) 
```


## Deep CART
as a baseline


```{r}
set.seed(2025)
cart_mod <- 
  decision_tree(mode = "classification",
                engine = "rpart",
                cost_complexity = 0,
                tree_depth = 30,
                min_n = 20) 

class_recipe <- 
  recipe(Status ~ ., data = credit_train)

cart_workflow <- 
  workflow() |> 
  add_model(cart_mod) |> 
  add_recipe(class_recipe)

cart_fit <- fit(cart_workflow,
                data = credit_train)

cart_class_boot_preds <- class_bootstrap(cart_workflow, credit_train, credit_test)

cart_class_tradeoff <- bias_var_mse_class(cart_class_boot_preds)
```

## Shallow CART

```{r}
set.seed(2025)
cart_short_mod <- 
  decision_tree(mode = "classification",
                engine = "rpart",
                cost_complexity = 0,
                tree_depth = 3,
                min_n = 20) 

class_recipe <- 
  recipe(Status ~ ., data = credit_train)

cart_short_workflow <- 
  workflow() |> 
  add_model(cart_short_mod) |> 
  add_recipe(class_recipe)

cart_short_fit <- fit(cart_short_workflow,
                      data = credit_train)

cart_short_class_boot_preds <- class_bootstrap(cart_short_workflow, credit_train, credit_test)

cart_short_class_tradeoff <- bias_var_mse_class(cart_short_class_boot_preds)
```

## Bagging
```{r}
set.seed(2025)
bag_mod <- 
  rand_forest(mode = "classification",
              engine = "ranger",
              mtry = ncol(credit_data) - 1,
              trees = 100,
              min_n = 20)  |>
  set_engine("ranger",
             probability = FALSE)

bag_workflow <- 
  workflow() |> 
  add_model(bag_mod) |> 
  add_recipe(class_recipe)

bag_fit <-
  bag_workflow |>
  fit(data = credit_train)

bag_class_boot_preds <- class_bootstrap(bag_workflow, credit_train, credit_test)

bag_class_tradeoff <- bias_var_mse_class(bag_class_boot_preds)
```

## RF
```{r}
set.seed(2025)
rf_mod <- 
  rand_forest(mode = "classification",
              engine = "ranger",
              mtry = floor(sqrt(ncol(credit_data) - 1)),
              trees = 100,
              min_n = 20)  |>
  set_engine("ranger",
             probability = FALSE)

rf_workflow <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(class_recipe)

rf_fit <-
  rf_workflow |>
  fit(data = credit_train)

rf_class_boot_preds <- class_bootstrap(rf_workflow, credit_train, credit_test)

rf_class_tradeoff <- bias_var_mse_class(rf_class_boot_preds)
```

### More complex - lots of predictors
```{r}
set.seed(2025)
credit_train_rand <- credit_train |>
  bind_cols(vroom::gen_tbl(rows = nrow(credit_train),
                           cols = 50,
                           col_types = rep(times = 50,list("d"))))
credit_test_rand <- credit_test |>
  bind_cols(vroom::gen_tbl(rows = nrow(credit_test),
                           cols = 50,
                           col_types = rep(times = 50,list("d"))))
set.seed(2025)
rf_mod <- 
  rand_forest(mode = "classification",
              engine = "ranger",
              mtry = floor(sqrt(ncol(credit_data) - 1)),
              trees = 100,
              min_n = 20)  |>
  set_engine("ranger",
             probability = FALSE)

class_recipe <- 
  recipe(Status ~ ., data = credit_train_rand)

rf_workflow <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(class_recipe)

rf_fit <-
  rf_workflow |>
  fit(data = credit_train_rand)

rf_small_class_boot_preds <- class_bootstrap(rf_workflow, credit_train_rand, credit_test_rand)

rf_small_class_tradeoff <- bias_var_mse_class(rf_small_class_boot_preds)
```

## comparison

```{r}
cart_short_class_tradeoff |>
  mutate(name = "2. CART Short") |>
  bind_rows(cart_class_tradeoff |>
              mutate(name = "1. CART Deep")) |>
  bind_rows(bag_class_tradeoff |>
              mutate(name = "3. Bagging")) |>
  bind_rows(rf_class_tradeoff |>
              mutate(name = "4. RF")) |>
  bind_rows(rf_small_class_tradeoff |>
              mutate(name = "5. RF small")) |>
  pivot_longer(cols = c(mean_bias_2, mean_var_2, irr_error),
               names_to = "variable",
               values_to = "value") |>
  ggplot(aes(x = name)) +
  geom_bar(aes(y = value, fill = variable),
           position = "dodge", stat = "identity")
```

Bias is not changing much, all we are doing is smoothing out the variance

## how well does CV and OOB approximate the error?
```{r}
cart_res <- fit_resamples(cart_workflow,
                          control = control_resamples(save_workflow = TRUE),
                          metrics = metric_set(accuracy),
                          resamples = credit_cv)

bag_res <- fit_resamples(bag_workflow,
                          control = control_resamples(save_workflow = TRUE),
                          metrics = metric_set(accuracy),
                          resamples = credit_cv)

rf_res <- fit_resamples(rf_workflow,
                          control = control_resamples(save_workflow = TRUE),
                          metrics = metric_set(accuracy),
                          resamples = credit_cv)

cart_res |> 
  collect_metrics()

1- cart_class_tradeoff$mean_loss

bag_res |>
  collect_metrics()

1 - bag_fit |> 
  extract_fit_engine() |>
  pluck("prediction.error") 

1 - bag_class_tradeoff$mean_loss

rf_res |>
  collect_metrics()

# why is the oob error so bad at estimating the true error? way worse than CV
1 - rf_fit |> 
  extract_fit_engine() |>
  pluck("prediction.error") 

1 - rf_class_tradeoff$mean_loss
```

## compare probability averaging with consensus voting

