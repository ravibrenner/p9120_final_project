---
title: "Ensemble Trees"
author: "Ravi Brenner"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
data(ames)
data(credit_data)
```

```{r}
set.seed(2025)

ames_split <- initial_split(ames, prop = 0.8)
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
ames_cv <- vfold_cv(ames_train)

credit_split <- initial_split(credit_data, prop = 0.8, strata = Status)
credit_train <- training(credit_split)
credit_test <- testing(credit_split)
credit_cv <- vfold_cv(credit_train)
```


# Deep CART
as a baseline

## Regression case

```{r}
set.seed(2025)
cart_mod <- 
  decision_tree(mode = "regression",
                engine = "rpart",
                cost_complexity = 0,
                tree_depth = 30,
                min_n = 20) 

reg_recipe <- 
  recipe(Sale_Price ~ ., data = ames_train)

cart_workflow <- 
  workflow() |> 
  add_model(cart_mod) |> 
  add_recipe(reg_recipe)

cart_fit <- fit(cart_workflow,
                data = ames_train)


# Calculate the test set bias, variance, MSE with bootstrapping
bootstrap_predictions <- function(workflow_in, train_data, test_data){
  fit_model <- function(split, workflow) {
    fit(workflow, data = training(split))
  }
  
  set.seed(2025)
  ames_bootstraps <- bootstraps(train_data, times = 100)
  
  all_predictions <-
    ames_bootstraps |>
    mutate(
      model_fit = map(splits, fit_model, workflow = workflow_in),
      predictions = map(model_fit, ~ predict(.x, new_data = test_data) |> rename(pred = .pred))
    )
  
  prediction_df <-
    all_predictions |>
    select(id, predictions) |>
    unnest(predictions) |>
    group_by(id) |>
    mutate(Sale_Price = rep(test_data$Sale_Price, length.out = n()),
           obs_id = row_number()) |>
    ungroup()
  
  return(prediction_df)
}

bias_var_mse <- function(pred_df){
  mse_df <-
    pred_df |>
    group_by(obs_id) |>
    summarise(
      bias_sq = (mean(pred) - mean(Sale_Price))^2,
      variance = stats::var(pred),
      mse = mean((pred - Sale_Price)^2),
      avg_sale_price = mean(Sale_Price)
    ) |>
    ungroup() |>
    summarise(
      mean_bias_sq = mean(bias_sq),
      mean_variance = mean(variance),
      mean_mse = mean(mse),
      irr_error = mean_mse - mean_bias_sq - mean_variance
    )
  return(mse_df)
}

cart_boot_preds <- bootstrap_predictions(cart_workflow, ames_train, ames_test)

cart_tradeoff <- bias_var_mse(cart_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```




# Shallow CART

```{r}
set.seed(2025)
cart_mod_short <- 
  decision_tree(mode = "regression",
                engine = "rpart",
                cost_complexity = 0,
                tree_depth = 3,
                min_n = 20) 

reg_recipe <- 
  recipe(Sale_Price ~ ., data = ames_train)

cart_short_workflow <- 
  workflow() |> 
  add_model(cart_mod_short) |> 
  add_recipe(reg_recipe)

cart_short_fit <- fit(cart_short_workflow,
                      data = ames_train)

cart_short_boot_preds <- bootstrap_predictions(cart_short_workflow, ames_train, ames_test)

cart_short_tradeoff <- bias_var_mse(cart_short_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```


-- misclassification, gini, or cross entropy loss for classification

## classification

often has high variance SHOW THIS VIA BOOTSTRAPPING?

# Bagging

```{r}
set.seed(2025)
bag_mod <- 
  rand_forest(mode = "regression",
              engine = "ranger",
              mtry = ncol(ames) - 1,
              trees = 100,
              min_n = 20) 

reg_recipe <- 
  recipe(Sale_Price ~ ., data = ames_train)

bag_workflow <- 
  workflow() |> 
  add_model(bag_mod) |> 
  add_recipe(reg_recipe)

bag_fit <-
  bag_workflow |>
  fit(data = ames_train)

# raw_predictions <- predict(bag_fit |> extract_fit_engine(), 
#                            data = ames_test, predict.all = TRUE)$predictions
# 
# bag_preds <- raw_predictions |> 
#   as_tibble() |>
#   mutate(obs_id = row_number()) |>
#   pivot_longer(cols = -obs_id,
#                names_to = "tree_id",
#                values_to = "pred") |>
#   inner_join(ames_test |>
#                mutate(obs_id = row_number()) |>
#                select(obs_id, Sale_Price))
# 
# bag_preds |>
#   group_by(obs_id) |>
#   summarize(Sale_Price = first(Sale_Price),
#             avg_pred = mean(pred)) |>
#   ungroup() |>
#   summarize(bias_sq = (mean(avg_pred) - mean(Sale_Price))^2,
#             variance = stats::var(avg_pred),
#             mse = mean((avg_pred - Sale_Price)^2)) |>
#   mutate(irr_err = mse - bias_sq - variance,
#          rmse = sqrt(mse))

# 
bag_boot_preds <- bootstrap_predictions(bag_workflow, ames_train, ames_test)

bag_tradeoff <- bias_var_mse(bag_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```


Show that variance is reduced relative to CART

# Random Forests

should reduce variance relative to bagging, especially when predictors are correlated may need to sim this

```{r}
set.seed(2025)
rf_mod <- 
  rand_forest(mode = "regression",
              engine = "ranger",
              mtry = floor((ncol(ames) - 1)/3),
              trees = 100,
              min_n = 20) 


reg_recipe <- 
  recipe(Sale_Price ~ ., data = ames_train)

rf_workflow <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(reg_recipe)

rf_fit <-
  rf_workflow |>
  fit(data = ames_train)


rf_boot_preds <- bootstrap_predictions(rf_workflow, ames_train, ames_test)

rf_tradeoff <- bias_var_mse(rf_boot_preds) |>
  mutate(rmse = sqrt(mean_mse))
```

## Too complex s.t. bias starts to increase more and mse starts to increase tooo
i think rf with a smaller mtry would work

## show that when num predictors = ncol(data), you get back same results as bagging

## compare probability averaging with consensus voting

## OOB vs cross validation?